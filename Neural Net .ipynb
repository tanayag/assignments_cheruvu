{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#using sigmoid and cross-entropy\n",
    "class creat_network(object):\n",
    "    \n",
    "    def __init__(self,len_x,len_h1,len_h2,len_y):    #define number of neurons in different layers\n",
    "        self.len_x = len_x\n",
    "        self.len_h1 = len_h1\n",
    "        self.len_h2 = len_h2\n",
    "        self.len_y = len_y\n",
    "        self.biases = [np.random.randn(i,1) for i in [len_h1,len_h2,len_y]]\n",
    "        self.weights = [np.random.randn(i,j) for i,j in zip([len_h1,len_h2,len_y],[len_x,len_h1,len_h2])]\n",
    "    \n",
    "\n",
    "\n",
    "        \n",
    "    def forward_pass(self,a):   #for 1st layer a=x(input)\n",
    "        for w,b in zip(self.weights,self.biases):\n",
    "            a = sigmoid(np.dot(w,a)+b)\n",
    "        return a\n",
    "    \n",
    "    \n",
    "    #len_m_batch: lenght of mini batch for SGD\n",
    "    #alpha: learning rate\n",
    "    #reg: l2 regularization parameter\n",
    "    \n",
    "    def sgd(self,train_data,test_data, epochs, len_m_batch, alpha, reg):   \n",
    "        len_test = len(test_data)\n",
    "        len_train = len(train_data)\n",
    "        for _ in xrange(epochs):\n",
    "            random.shuffle(train_data)\n",
    "            mini_batches = [train_data[i:len_m_batch+i] for i in xrange(0,len_train,len_m_batch)] \n",
    "            \n",
    "            for batch in mini_batches:\n",
    "                w_after_iteration = [np.zeros(w.shape) for w in self.weights]\n",
    "                b_after_iteration = [np.zeros(b.shape) for b in self.biases]\n",
    "                for x,y in batch:\n",
    "                    delta_w,delta_b = self.backpropogate(x,y)\n",
    "                    w_after_iteration = [w+dw for w,dw in zip(w_after_iteration,delta_w)]\n",
    "                    b_after_iteration = [b+db for b,db in zip(b_after_iteration,delta_b)]\n",
    "                    \n",
    "                self.weights = [((1-alpha*(reg/len_train))*w-((alpha*1.0)/len_m_batch)*dw) for w,dw in zip(self.weights,w_after_iteration)] #using l2 regularization\n",
    "                self.biases = [(b-((alpha*1.0)/len_m_batch)*db) for b,db in zip(self.biases,b_after_iteration)]\n",
    "                \n",
    "            print(\"Epoch {0}: \\nTest Accuracy: {1}/{2}\\n\\n\".format(_,self.evaluate_test(test_data),len_test))\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "    def backpropogate(self,x,y):\n",
    "        backpass_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        backpass_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        a = x\n",
    "        a_list = [a]\n",
    "        z_list = [] \n",
    "        for w,b in zip(self.weights,self.biases):\n",
    "            z = np.dot(w,a)+b\n",
    "            z_list.append(z)\n",
    "            a = sigmoid(z)\n",
    "            a_list.append(a)\n",
    "            \n",
    "        delta = derivative_cost(a_list[-1],y)\n",
    "        backpass_b[-1] = delta\n",
    "        backpass_w[-1] = np.dot(delta,(a_list[-2].transpose()))\n",
    "        \n",
    "        for l in range(2,4):\n",
    "            z = z_list[-l]\n",
    "            sig_derivative = sigmoid(z)*(1-sigmoid(z))\n",
    "            delta = np.dot(self.weights[-l+1].transpose(), delta) * sig_derivative\n",
    "            backpass_b[-l] = delta\n",
    "            backpass_w[-l] = np.dot(delta, a_list[-l-1].transpose())\n",
    "            \n",
    "        return (backpass_w,backpass_b)\n",
    "    \n",
    "    def evaluate_test(self, data):\n",
    "        results = [(np.argmax(self.forward_pass(x)), y) for (x, y) in data]\n",
    "        return sum(int(x == y) for (x, y) in results)\n",
    "        \n",
    "    def evaluate_train(self,data):\n",
    "        results = [(np.argmax(self.forward_pass(x)), np.agrmax(y)) for (x, y) in data]\n",
    "        #print results\n",
    "        return sum(int(x == y) for (x, y) in results)\n",
    "        \n",
    "def cost_fun(a,y):\n",
    "    return -np.sum(((1-y)*np.log(1-a))+((y)*np.log(a))) #cross-entropy cost func.\n",
    "    \n",
    "        \n",
    "def derivative_cost(a,y):\n",
    "    return a-y\n",
    "\n",
    "\n",
    "def shuffle(data):\n",
    "    np.random.seed(0)\n",
    "    np.random.shuffle(data)\n",
    "    return data\n",
    "\n",
    "def sigmoid(f):\n",
    "    return 1.0/(1+np.exp(-f))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#to use:\n",
    "#net = creat_network(x, lenth_h1, length_h2, classes)\n",
    "#net.sgd(training_data,test_data,epochs,lenght_mini_batch,learning_rate,regularization_parameter)\n",
    "\n",
    "#vectorize(one hot encode) target_classes for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
